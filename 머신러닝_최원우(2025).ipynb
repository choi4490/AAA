{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMDlSKutCHBfyriav/BMKDA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/choi4490/AAA/blob/main/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D_%EC%B5%9C%EC%9B%90%EC%9A%B0(2025).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 아파트건설 예측(클로드도움)"
      ],
      "metadata": {
        "id": "irUCKS90Ggdd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "아파트 건설공사 데이터를 활용한 머신러닝 모델링을 위해 분석해드리겠습니다.\n",
        "최적 모델링 기법 분석\n",
        "\n",
        "1. 추천 모델링 기법\n",
        "주요 추천 모델:\n",
        "Random Forest: 건설 프로젝트의 복잡한 비선형 관계를 잘 포착하며, 특성 중요도 분석 가능\n",
        "XGBoost/LightGBM: 높은 예측 정확도와 결측값 처리 능력\n",
        "Multiple Linear Regression: 해석 가능성이 높아 건설업계에서 선호\n",
        "Neural Network: 복잡한 패턴 학습 가능하지만 데이터 수가 제한적\n",
        "50개 데이터 고려시 최적 선택:\n",
        "Random Forest (1순위): 소규모 데이터셋에서도 안정적 성능\n",
        "XGBoost (2순위): 과적합 방지 기능 우수\n",
        "Ensemble 방법: 여러 모델 조합으로 안정성 향상\n",
        "\n",
        "2. 데이터 전처리 고려사항\n",
        "물가상승률 정규화: 기준년도 대비 조정\n",
        "공사유형 인코딩: 원핫인코딩 또는 라벨인코딩\n",
        "시계열 특성: 시작년월을 기준으로 한 경과시간 변환\n",
        "이상치 처리: 건설비용의 극값 처리\n",
        "\n",
        "모델 활용 가이드\n",
        "\n",
        "3. 데이터 준비사항\n",
        "필수 전처리:\n",
        "결측값 처리 (평균값 대체 또는 도메인 지식 활용)\n",
        "이상치 탐지 및 처리 (IQR 방법 사용)\n",
        "물가지수 정규화 (기준년도 설정)\n",
        "범주형 변수 인코딩\n",
        "\n",
        "4. 모델 성능 향상 방안\n",
        "데이터 부족 해결책:\n",
        "데이터 증강: 유사 프로젝트 데이터 수집\n",
        "외부 데이터 활용: 건설물가정보, 지역별 인건비 등\n",
        "도메인 지식 활용: 건설업계 전문가 피드백 반영\n",
        "모델 앙상블:\n",
        "\n",
        "5. 실무 적용 시 고려사항\n",
        "모델 업데이트:\n",
        "신규 프로젝트 완료시 데이터 추가 학습\n",
        "계절성 및 경제 상황 변화 반영\n",
        "정기적 모델 재훈련 (분기별 권장)\n",
        "예측 신뢰도 관리:\n",
        "예측 구간(Prediction Interval) 제공\n",
        "유사 과거 프로젝트 참조 정보 제공\n",
        "전문가 검토 프로세스 포함\n",
        "주요 예측 타겟별 특징:\n",
        "공사기간: 날씨, 인허가 지연 등 외부 요인 고려\n",
        "비용: 원자재 가격 변동성 높음, 월별 업데이트 필요\n",
        "인력: 숙련도별 차등 적용, 지역별 인력 수급 상황 반영\n",
        "50개 데이터로는 Deep Learning보다 Random Forest + XGBoost 앙상블이 최적이며, 지속적인 데이터 수집과 모델 업데이트가 예측 정확도 향상의 핵심입니다."
      ],
      "metadata": {
        "id": "EmQp8-A5GgKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "paE2jsCXGdKO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import xgboost as xgb\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class ConstructionCostPredictor:\n",
        "    def __init__(self):\n",
        "        self.models = {}\n",
        "        self.scalers = {}\n",
        "        self.encoders = {}\n",
        "        self.feature_importance = {}\n",
        "\n",
        "    def load_and_preprocess_data(self, data_path=None):\n",
        "        \"\"\"\n",
        "        데이터 로드 및 전처리\n",
        "        실제 사용시 data_path에 Excel/CSV 파일 경로 입력\n",
        "        \"\"\"\n",
        "        # 샘플 데이터 생성 (실제 데이터로 교체 필요)\n",
        "        np.random.seed(42)\n",
        "        n_samples = 50\n",
        "\n",
        "        data = {\n",
        "            # 시간 관련\n",
        "            '시작년월': pd.date_range('2020-01', periods=n_samples, freq='M'),\n",
        "            '준공년월': pd.date_range('2021-01', periods=n_samples, freq='M'),\n",
        "            '전체예산실행승인년월': pd.date_range('2019-12', periods=n_samples, freq='M'),\n",
        "\n",
        "            # 물가 관련\n",
        "            '공사기간내물가상승률': np.random.uniform(0.02, 0.08, n_samples),\n",
        "            '철근레미콘물가상승률': np.random.uniform(0.03, 0.12, n_samples),\n",
        "            '보통인부단가': np.random.uniform(150000, 200000, n_samples),\n",
        "\n",
        "            # 프로젝트 특성\n",
        "            '공사유형': np.random.choice(['아파트', '오피스텔', '주상복합'], n_samples),\n",
        "            '지하층수': np.random.randint(1, 4, n_samples),\n",
        "            '지상최고층수': np.random.randint(10, 35, n_samples),\n",
        "            '아파트동수': np.random.randint(3, 15, n_samples),\n",
        "            '세대수': np.random.randint(200, 1500, n_samples),\n",
        "            '연면적': np.random.uniform(30000, 150000, n_samples),\n",
        "            '대지면적': np.random.uniform(10000, 50000, n_samples),\n",
        "            '마감수준': np.random.choice(['A', 'B', 'C', 'D'], n_samples),\n",
        "\n",
        "            # 인력 관련\n",
        "            '현장직원수': np.random.randint(15, 50, n_samples),\n",
        "\n",
        "            # 비용 관련\n",
        "            '외주계약금액': np.random.uniform(20000000000, 80000000000, n_samples),\n",
        "            '원재료금액': np.random.uniform(15000000000, 60000000000, n_samples),\n",
        "            '경비금액': np.random.uniform(2000000000, 8000000000, n_samples),\n",
        "            '도급금액': np.random.uniform(50000000000, 200000000000, n_samples),\n",
        "        }\n",
        "\n",
        "        df = pd.DataFrame(data)\n",
        "\n",
        "        # 타겟 변수 생성 (실제 데이터에서는 실제 값 사용)\n",
        "        df['최종공사개월수'] = (df['준공년월'] - df['시작년월']).dt.days / 30\n",
        "        df['실행예산금액'] = df['도급금액'] * np.random.uniform(0.85, 1.15, n_samples)\n",
        "        df['실제투입원가'] = df['실행예산금액'] * np.random.uniform(0.9, 1.1, n_samples)\n",
        "        df['적정HR인사발령'] = np.round(df['연면적'] / 3000 + df['세대수'] / 100).astype(int)\n",
        "\n",
        "        return df\n",
        "\n",
        "    def feature_engineering(self, df):\n",
        "        \"\"\"특성 엔지니어링\"\"\"\n",
        "        df_processed = df.copy()\n",
        "\n",
        "        # 날짜 특성 추출\n",
        "        df_processed['시작년도'] = df_processed['시작년월'].dt.year\n",
        "        df_processed['시작월'] = df_processed['시작년월'].dt.month\n",
        "        df_processed['준공년도'] = df_processed['준공년월'].dt.year\n",
        "\n",
        "        # 프로젝트 규모 지표\n",
        "        df_processed['세대당연면적'] = df_processed['연면적'] / df_processed['세대수']\n",
        "        df_processed['동당세대수'] = df_processed['세대수'] / df_processed['아파트동수']\n",
        "        df_processed['용적률'] = df_processed['연면적'] / df_processed['대지면적']\n",
        "\n",
        "        # 비용 효율성 지표\n",
        "        df_processed['세대당도급금액'] = df_processed['도급금액'] / df_processed['세대수']\n",
        "        df_processed['연면적당도급금액'] = df_processed['도급금액'] / df_processed['연면적']\n",
        "\n",
        "        # 물가 조정된 비용 (2020년 기준)\n",
        "        base_year = 2020\n",
        "        df_processed['물가조정계수'] = (1 + df_processed['공사기간내물가상승률']) ** (df_processed['시작년도'] - base_year)\n",
        "        df_processed['물가조정도급금액'] = df_processed['도급금액'] / df_processed['물가조정계수']\n",
        "\n",
        "        # 카테고리 인코딩\n",
        "        le_type = LabelEncoder()\n",
        "        le_finish = LabelEncoder()\n",
        "\n",
        "        df_processed['공사유형_encoded'] = le_type.fit_transform(df_processed['공사유형'])\n",
        "        df_processed['마감수준_encoded'] = le_finish.fit_transform(df_processed['마감수준'])\n",
        "\n",
        "        self.encoders['공사유형'] = le_type\n",
        "        self.encoders['마감수준'] = le_finish\n",
        "\n",
        "        return df_processed\n",
        "\n",
        "    def prepare_features(self, df):\n",
        "        \"\"\"모델링용 특성 준비\"\"\"\n",
        "        feature_columns = [\n",
        "            '지하층수', '지상최고층수', '아파트동수', '세대수', '연면적', '대지면적',\n",
        "            '현장직원수', '공사기간내물가상승률', '철근레미콘물가상승률', '보통인부단가',\n",
        "            '외주계약금액', '원재료금액', '경비금액', '도급금액', '물가조정도급금액',\n",
        "            '공사유형_encoded', '마감수준_encoded', '시작년도', '시작월',\n",
        "            '세대당연면적', '동당세대수', '용적률', '세대당도급금액', '연면적당도급금액'\n",
        "        ]\n",
        "\n",
        "        target_columns = ['최종공사개월수', '실행예산금액', '실제투입원가', '적정HR인사발령']\n",
        "\n",
        "        X = df[feature_columns]\n",
        "        y = df[target_columns]\n",
        "\n",
        "        return X, y, feature_columns, target_columns\n",
        "\n",
        "    def train_models(self, X, y, target_columns):\n",
        "        \"\"\"다중 타겟 모델 훈련\"\"\"\n",
        "        # 특성 스케일링\n",
        "        scaler = StandardScaler()\n",
        "        X_scaled = scaler.fit_transform(X)\n",
        "        self.scalers['features'] = scaler\n",
        "\n",
        "        # 각 타겟별로 모델 훈련\n",
        "        for target in target_columns:\n",
        "            print(f\"\\n=== {target} 모델 훈련 중 ===\")\n",
        "\n",
        "            # 타겟 스케일링\n",
        "            target_scaler = StandardScaler()\n",
        "            y_target = target_scaler.fit_transform(y[target].values.reshape(-1, 1)).ravel()\n",
        "            self.scalers[target] = target_scaler\n",
        "\n",
        "            # 데이터 분할\n",
        "            X_train, X_test, y_train, y_test = train_test_split(\n",
        "                X_scaled, y_target, test_size=0.2, random_state=42\n",
        "            )\n",
        "\n",
        "            # 모델들 정의\n",
        "            models = {\n",
        "                'RandomForest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
        "                'XGBoost': xgb.XGBRegressor(n_estimators=100, random_state=42),\n",
        "                'LinearRegression': LinearRegression()\n",
        "            }\n",
        "\n",
        "            best_model = None\n",
        "            best_score = -np.inf\n",
        "\n",
        "            # 각 모델 훈련 및 평가\n",
        "            for name, model in models.items():\n",
        "                # 교차 검증\n",
        "                cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='r2')\n",
        "                mean_cv_score = np.mean(cv_scores)\n",
        "\n",
        "                # 전체 데이터로 훈련\n",
        "                model.fit(X_train, y_train)\n",
        "\n",
        "                # 테스트 예측\n",
        "                y_pred = model.predict(X_test)\n",
        "                test_score = r2_score(y_test, y_pred)\n",
        "\n",
        "                print(f\"{name}: CV R² = {mean_cv_score:.3f}, Test R² = {test_score:.3f}\")\n",
        "\n",
        "                if mean_cv_score > best_score:\n",
        "                    best_score = mean_cv_score\n",
        "                    best_model = model\n",
        "\n",
        "            self.models[target] = best_model\n",
        "\n",
        "            # 특성 중요도 저장 (Random Forest의 경우)\n",
        "            if hasattr(best_model, 'feature_importances_'):\n",
        "                self.feature_importance[target] = best_model.feature_importances_\n",
        "\n",
        "    def predict(self, X_new):\n",
        "        \"\"\"새로운 데이터에 대한 예측\"\"\"\n",
        "        # 특성 스케일링\n",
        "        X_scaled = self.scalers['features'].transform(X_new)\n",
        "\n",
        "        predictions = {}\n",
        "        for target, model in self.models.items():\n",
        "            # 예측\n",
        "            y_pred_scaled = model.predict(X_scaled)\n",
        "\n",
        "            # 역스케일링\n",
        "            y_pred = self.scalers[target].inverse_transform(y_pred_scaled.reshape(-1, 1)).ravel()\n",
        "            predictions[target] = y_pred\n",
        "\n",
        "        return predictions\n",
        "\n",
        "    def plot_feature_importance(self, feature_columns, target='최종공사개월수'):\n",
        "        \"\"\"특성 중요도 시각화\"\"\"\n",
        "        if target in self.feature_importance:\n",
        "            importance = self.feature_importance[target]\n",
        "            feature_imp_df = pd.DataFrame({\n",
        "                'feature': feature_columns,\n",
        "                'importance': importance\n",
        "            }).sort_values('importance', ascending=False)\n",
        "\n",
        "            plt.figure(figsize=(10, 8))\n",
        "            sns.barplot(data=feature_imp_df.head(15), x='importance', y='feature')\n",
        "            plt.title(f'{target} - 특성 중요도')\n",
        "            plt.xlabel('중요도')\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "            return feature_imp_df\n",
        "\n",
        "    def evaluate_models(self, X_test, y_test, target_columns):\n",
        "        \"\"\"모델 성능 평가\"\"\"\n",
        "        results = {}\n",
        "\n",
        "        for target in target_columns:\n",
        "            if target in self.models:\n",
        "                model = self.models[target]\n",
        "\n",
        "                # 예측\n",
        "                X_scaled = self.scalers['features'].transform(X_test)\n",
        "                y_pred_scaled = model.predict(X_scaled)\n",
        "\n",
        "                # 역스케일링\n",
        "                y_pred = self.scalers[target].inverse_transform(y_pred_scaled.reshape(-1, 1)).ravel()\n",
        "                y_true = y_test[target].values\n",
        "\n",
        "                # 평가 지표 계산\n",
        "                mae = mean_absolute_error(y_true, y_pred)\n",
        "                mse = mean_squared_error(y_true, y_pred)\n",
        "                rmse = np.sqrt(mse)\n",
        "                r2 = r2_score(y_true, y_pred)\n",
        "\n",
        "                results[target] = {\n",
        "                    'MAE': mae,\n",
        "                    'RMSE': rmse,\n",
        "                    'R²': r2\n",
        "                }\n",
        "\n",
        "                print(f\"\\n{target} 성능:\")\n",
        "                print(f\"  MAE: {mae:,.2f}\")\n",
        "                print(f\"  RMSE: {rmse:,.2f}\")\n",
        "                print(f\"  R²: {r2:.3f}\")\n",
        "\n",
        "        return results\n",
        "\n",
        "# 사용 예제\n",
        "def main():\n",
        "    # 모델 인스턴스 생성\n",
        "    predictor = ConstructionCostPredictor()\n",
        "\n",
        "    # 데이터 로드 및 전처리\n",
        "    print(\"데이터 로드 및 전처리 중...\")\n",
        "    df = predictor.load_and_preprocess_data()\n",
        "    df_processed = predictor.feature_engineering(df)\n",
        "\n",
        "    # 특성 및 타겟 준비\n",
        "    X, y, feature_columns, target_columns = predictor.prepare_features(df_processed)\n",
        "\n",
        "    print(f\"특성 수: {len(feature_columns)}\")\n",
        "    print(f\"샘플 수: {len(X)}\")\n",
        "    print(f\"타겟 변수: {target_columns}\")\n",
        "\n",
        "    # 모델 훈련\n",
        "    print(\"\\n모델 훈련 시작...\")\n",
        "    predictor.train_models(X, y, target_columns)\n",
        "\n",
        "    # 신규 프로젝트 예측 예제\n",
        "    print(\"\\n=== 신규 프로젝트 예측 예제 ===\")\n",
        "\n",
        "    # 신규 프로젝트 데이터 (예시)\n",
        "    new_project = pd.DataFrame({\n",
        "        '지하층수': [2],\n",
        "        '지상최고층수': [25],\n",
        "        '아파트동수': [8],\n",
        "        '세대수': [800],\n",
        "        '연면적': [80000],\n",
        "        '대지면적': [25000],\n",
        "        '현장직원수': [30],\n",
        "        '공사기간내물가상승률': [0.05],\n",
        "        '철근레미콘물가상승률': [0.08],\n",
        "        '보통인부단가': [170000],\n",
        "        '외주계약금액': [40000000000],\n",
        "        '원재료금액': [30000000000],\n",
        "        '경비금액': [5000000000],\n",
        "        '도급금액': [100000000000],\n",
        "        '물가조정도급금액': [95000000000],\n",
        "        '공사유형_encoded': [0],  # 실제로는 인코더 사용\n",
        "        '마감수준_encoded': [1],  # 실제로는 인코더 사용\n",
        "        '시작년도': [2024],\n",
        "        '시작월': [3],\n",
        "        '세대당연면적': [100],\n",
        "        '동당세대수': [100],\n",
        "        '용적률': [3.2],\n",
        "        '세대당도급금액': [125000000],\n",
        "        '연면적당도급금액': [1250000]\n",
        "    })\n",
        "\n",
        "    # 예측 수행\n",
        "    predictions = predictor.predict(new_project)\n",
        "\n",
        "    print(\"\\n신규 프로젝트 예측 결과:\")\n",
        "    for target, pred_value in predictions.items():\n",
        "        if target == '최종공사개월수':\n",
        "            print(f\"  {target}: {pred_value[0]:.1f} 개월\")\n",
        "        elif target == '적정HR인사발령':\n",
        "            print(f\"  {target}: {int(pred_value[0])} 명\")\n",
        "        else:\n",
        "            print(f\"  {target}: {pred_value[0]:,.0f} 원\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "# 실제 사용을 위한 추가 함수들\n",
        "\n",
        "def load_excel_data(file_path):\n",
        "    \"\"\"Excel 파일에서 데이터 로드\"\"\"\n",
        "    try:\n",
        "        df = pd.read_excel(file_path)\n",
        "        print(f\"데이터 로드 완료: {len(df)}개 레코드\")\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"데이터 로드 실패: {e}\")\n",
        "        return None\n",
        "\n",
        "def save_model(predictor, model_path):\n",
        "    \"\"\"모델 저장\"\"\"\n",
        "    import pickle\n",
        "    with open(model_path, 'wb') as f:\n",
        "        pickle.dump(predictor, f)\n",
        "    print(f\"모델 저장 완료: {model_path}\")\n",
        "\n",
        "def load_model(model_path):\n",
        "    \"\"\"모델 로드\"\"\"\n",
        "    import pickle\n",
        "    with open(model_path, 'rb') as f:\n",
        "        predictor = pickle.load(f)\n",
        "    print(f\"모델 로드 완료: {model_path}\")\n",
        "    return predictor\n",
        "\n",
        "# 데이터 품질 확인 함수\n",
        "def check_data_quality(df):\n",
        "    \"\"\"데이터 품질 확인\"\"\"\n",
        "    print(\"=== 데이터 품질 확인 ===\")\n",
        "    print(f\"전체 레코드 수: {len(df)}\")\n",
        "    print(f\"전체 컬럼 수: {len(df.columns)}\")\n",
        "    print(f\"결측값 비율:\")\n",
        "    print((df.isnull().sum() / len(df) * 100).round(2))\n",
        "    print(f\"\\n수치형 변수 기본 통계:\")\n",
        "    print(df.describe())"
      ]
    }
  ]
}